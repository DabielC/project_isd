{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:53:21.109306Z","iopub.status.busy":"2024-09-28T07:53:21.108884Z","iopub.status.idle":"2024-09-28T07:53:33.883873Z","shell.execute_reply":"2024-09-28T07:53:33.882706Z","shell.execute_reply.started":"2024-09-28T07:53:21.109259Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:54:18.363519Z","iopub.status.busy":"2024-09-28T07:54:18.363131Z","iopub.status.idle":"2024-09-28T07:54:18.369356Z","shell.execute_reply":"2024-09-28T07:54:18.368442Z","shell.execute_reply.started":"2024-09-28T07:54:18.363485Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2 as cv\n","import torch\n","import os\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchsummary import summary\n","from torchvision import models\n","from PIL import Image\n","import torchvision.models as models"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:55:41.364537Z","iopub.status.busy":"2024-09-28T07:55:41.363701Z","iopub.status.idle":"2024-09-28T07:55:41.385842Z","shell.execute_reply":"2024-09-28T07:55:41.384960Z","shell.execute_reply.started":"2024-09-28T07:55:41.364495Z"},"trusted":true},"outputs":[],"source":["import torchvision.transforms.v2 as transforms"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:55:42.594553Z","iopub.status.busy":"2024-09-28T07:55:42.594096Z","iopub.status.idle":"2024-09-28T07:55:42.604114Z","shell.execute_reply":"2024-09-28T07:55:42.602995Z","shell.execute_reply.started":"2024-09-28T07:55:42.594514Z"},"trusted":true},"outputs":[],"source":["def read_image(folders, target_size=(190, 250)):\n","    image_array = []\n","    label = []\n","    # Loop through each folder provided in the list of folders\n","    for folder in folders:\n","        # Iterate over the classes/subdirectories inside the folder\n","        for i in os.listdir(folder):\n","            class_folder = os.path.join(folder, i)  # Get the full path of the class folder\n","            # Get all image files with specified extensions\n","            image_files = [f for f in os.listdir(class_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n","            # Iterate over each image file in the class folder\n","            for j in image_files:\n","                image_path = os.path.join(class_folder, j)  # Get the full path of the image file\n","                image = cv.imread(image_path)  # Read the image\n","                image = cv.cvtColor(image, cv.COLOR_BGR2RGB)  # Convert the image from BGR to RGB color format\n","#                 image = cv.resize(image, target_size)  # Resize the image (commented out)\n","                image_array.append(image)  # Append the image to the image array\n","                label.append(i)  # Append the class label\n","    # Return the image array and labels as numpy arrays\n","    return np.array(image_array), np.array(label)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:55:45.347223Z","iopub.status.busy":"2024-09-28T07:55:45.346553Z","iopub.status.idle":"2024-09-28T07:57:01.702500Z","shell.execute_reply":"2024-09-28T07:57:01.701684Z","shell.execute_reply.started":"2024-09-28T07:55:45.347183Z"},"trusted":true},"outputs":[],"source":["train, label = read_image(['/kaggle/input/dataset-for-yolo-190x250/Dataset_(190x250)/train', '/kaggle/input/dataset-for-yolo-190x250/Dataset_(190x250)/val'])"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:57:39.261930Z","iopub.status.busy":"2024-09-28T07:57:39.261050Z","iopub.status.idle":"2024-09-28T07:57:39.821044Z","shell.execute_reply":"2024-09-28T07:57:39.818265Z","shell.execute_reply.started":"2024-09-28T07:57:39.261890Z"},"trusted":true},"outputs":[],"source":["x_train, x_val, y_train, y_val = train_test_split(train, label, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:57:41.375531Z","iopub.status.busy":"2024-09-28T07:57:41.375134Z","iopub.status.idle":"2024-09-28T07:57:41.382081Z","shell.execute_reply":"2024-09-28T07:57:41.381128Z","shell.execute_reply.started":"2024-09-28T07:57:41.375493Z"},"trusted":true},"outputs":[],"source":["class NumpyArrayDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images  # Store the images (numpy arrays)\n","        self.labels = labels  # Store the corresponding labels\n","        self.transform = transform  # Optional transform to be applied on a sample\n","\n","    def __len__(self):\n","        # Return the total number of images in the dataset\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # Retrieve an image and its corresponding label by index\n","        image = self.images[idx]\n","        label = self.labels[idx]\n","\n","        # Convert the numpy array image to a PIL image\n","        image = Image.fromarray(image)\n","\n","        # Apply the transform (if provided) to the image\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # Return the transformed image and its label\n","        return image, label\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:57:44.838203Z","iopub.status.busy":"2024-09-28T07:57:44.837562Z","iopub.status.idle":"2024-09-28T07:57:44.845182Z","shell.execute_reply":"2024-09-28T07:57:44.844285Z","shell.execute_reply.started":"2024-09-28T07:57:44.838134Z"},"trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally\n","    transforms.RandomRotation(degrees=10),   # Randomly rotate the image by up to 10 degrees\n","    transforms.RandomResizedCrop(size=(190, 250), scale=(0.8, 1.0)),  # Randomly crop and resize the image\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly change the brightness, contrast, saturation, and hue\n","    transforms.ToTensor(),  # Convert the image to a tensor\n","    transforms.ConvertImageDtype(torch.float32),  # Convert the image to float32\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize the image\n","])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T19:03:45.152726Z","iopub.status.busy":"2024-09-27T19:03:45.152148Z","iopub.status.idle":"2024-09-27T19:03:45.157784Z","shell.execute_reply":"2024-09-27T19:03:45.156874Z","shell.execute_reply.started":"2024-09-27T19:03:45.152687Z"},"trusted":true},"outputs":[],"source":["# train_transform = transforms.Compose([\n","#     transforms.Grayscale(num_output_channels=3),\n","#     transforms.ToTensor(),\n","#     transforms.ConvertImageDtype(torch.float32),\n","#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n","# ])"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:57:46.987804Z","iopub.status.busy":"2024-09-28T07:57:46.987420Z","iopub.status.idle":"2024-09-28T07:57:46.993609Z","shell.execute_reply":"2024-09-28T07:57:46.992609Z","shell.execute_reply.started":"2024-09-28T07:57:46.987767Z"},"trusted":true},"outputs":[],"source":["val_transform = transforms.Compose([\n","    # Convert image to grayscale and output 3 channels (R, G, B)\n","    transforms.Grayscale(num_output_channels=3),\n","    \n","    # Convert the image to a PyTorch tensor\n","    transforms.ToTensor(),\n","    \n","    # Convert the image tensor to dtype float32\n","    transforms.ConvertImageDtype(torch.float32),\n","    \n","    # Normalize the image tensor by applying a mean and standard deviation\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n","])"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:57:49.446218Z","iopub.status.busy":"2024-09-28T07:57:49.445556Z","iopub.status.idle":"2024-09-28T07:57:49.450631Z","shell.execute_reply":"2024-09-28T07:57:49.449767Z","shell.execute_reply.started":"2024-09-28T07:57:49.446176Z"},"trusted":true},"outputs":[],"source":["train_dataset = NumpyArrayDataset(x_train, y_train, transform=train_transform)\n","val_dataset = NumpyArrayDataset(x_val, y_val, transform=val_transform)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:57:51.188611Z","iopub.status.busy":"2024-09-28T07:57:51.187702Z","iopub.status.idle":"2024-09-28T07:57:51.193268Z","shell.execute_reply":"2024-09-28T07:57:51.192351Z","shell.execute_reply.started":"2024-09-28T07:57:51.188567Z"},"trusted":true},"outputs":[],"source":["# Create a DataLoader for the training dataset\n","# Batch size of 4, shuffle the data to ensure random sampling for each epoch\n","trainloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","\n","# Create a DataLoader for the validation dataset\n","# Batch size of 4, shuffle the data to ensure random sampling for validation\n","valloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["## YOLO Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-09-27T16:24:30.466865Z","iopub.status.busy":"2024-09-27T16:24:30.465881Z","iopub.status.idle":"2024-09-27T16:24:44.425280Z","shell.execute_reply":"2024-09-27T16:24:44.424111Z","shell.execute_reply.started":"2024-09-27T16:24:30.466813Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-09-27T16:24:47.887297Z","iopub.status.busy":"2024-09-27T16:24:47.886365Z","iopub.status.idle":"2024-09-27T16:25:01.737072Z","shell.execute_reply":"2024-09-27T16:25:01.736052Z","shell.execute_reply.started":"2024-09-27T16:24:47.887256Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip install -U ipywidgets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T16:25:06.947432Z","iopub.status.busy":"2024-09-27T16:25:06.947011Z","iopub.status.idle":"2024-09-27T16:25:07.356200Z","shell.execute_reply":"2024-09-27T16:25:07.355433Z","shell.execute_reply.started":"2024-09-27T16:25:06.947393Z"},"trusted":true},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T16:25:13.279555Z","iopub.status.busy":"2024-09-27T16:25:13.278714Z","iopub.status.idle":"2024-09-27T16:25:14.317368Z","shell.execute_reply":"2024-09-27T16:25:14.316213Z","shell.execute_reply.started":"2024-09-27T16:25:13.279516Z"},"trusted":true},"outputs":[],"source":["# Load a pretrained YOLOv8 model\n","# model = YOLO('https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8l-face.pt')\n","# model = YOLO('https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8n-face.pt')\n","# model = YOLO('yolov8l-cls.pt')\n","model = YOLO('yolov8x-cls.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-09-26T00:31:24.564347Z","iopub.status.busy":"2024-09-26T00:31:24.563856Z","iopub.status.idle":"2024-09-26T00:31:24.577186Z","shell.execute_reply":"2024-09-26T00:31:24.576083Z","shell.execute_reply.started":"2024-09-26T00:31:24.564300Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["model.model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T16:25:36.462864Z","iopub.status.busy":"2024-09-27T16:25:36.462215Z","iopub.status.idle":"2024-09-27T16:58:16.440158Z","shell.execute_reply":"2024-09-27T16:58:16.438970Z","shell.execute_reply.started":"2024-09-27T16:25:36.462823Z"},"trusted":true},"outputs":[],"source":["model.train(\n","    data='/kaggle/input/dataset-for-yolo-190x250/Dataset_(190x250)',\n","    epochs=15,\n","    imgsz=(190, 250),\n","    device='0',\n","    verbose=True,\n","    lr0=0.001,\n","    batch=4,\n","    optimizer='Adam'\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T16:59:37.385173Z","iopub.status.busy":"2024-09-27T16:59:37.384119Z","iopub.status.idle":"2024-09-27T16:59:37.860617Z","shell.execute_reply":"2024-09-27T16:59:37.859423Z","shell.execute_reply.started":"2024-09-27T16:59:37.385126Z"},"trusted":true},"outputs":[],"source":["model.save(\"/kaggle/working/trained_yolov8x-cls_2.pt\")"]},{"cell_type":"markdown","metadata":{},"source":["# Trainning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:48:43.642396Z","iopub.status.busy":"2024-09-28T07:48:43.642080Z","iopub.status.idle":"2024-09-28T07:51:01.430863Z","shell.execute_reply":"2024-09-28T07:51:01.429508Z","shell.execute_reply.started":"2024-09-28T07:48:43.642353Z"},"trusted":true},"outputs":[],"source":["!pip install facenet_pytorch"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T07:51:56.217191Z","iopub.status.busy":"2024-09-28T07:51:56.216803Z","iopub.status.idle":"2024-09-28T07:51:56.221436Z","shell.execute_reply":"2024-09-28T07:51:56.220470Z","shell.execute_reply.started":"2024-09-28T07:51:56.217153Z"},"trusted":true},"outputs":[],"source":["# from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n","from facenet_pytorch import InceptionResnetV1\n","# from torchvision import models\n","# from torchvision.models import googlenet, GoogLeNet_Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:01:44.002986Z","iopub.status.busy":"2024-09-28T09:01:44.002600Z","iopub.status.idle":"2024-09-28T09:01:49.834847Z","shell.execute_reply":"2024-09-28T09:01:49.833821Z","shell.execute_reply.started":"2024-09-28T09:01:44.002950Z"},"trusted":true},"outputs":[],"source":["# model = models.vgg19_bn(pretrained='casia-webface')\n","# model = InceptionResnetV1(pretrained='casia-webface')\n","# model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n","# model = googlenet(weights=GoogLeNet_Weights.IMAGENET1K_V1)\n","# model = models.densenet161(pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:00.793417Z","iopub.status.busy":"2024-09-28T09:02:00.793007Z","iopub.status.idle":"2024-09-28T09:02:00.970505Z","shell.execute_reply":"2024-09-28T09:02:00.969633Z","shell.execute_reply.started":"2024-09-28T09:02:00.793377Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:05.045007Z","iopub.status.busy":"2024-09-28T09:02:05.044624Z","iopub.status.idle":"2024-09-28T09:02:05.086663Z","shell.execute_reply":"2024-09-28T09:02:05.085676Z","shell.execute_reply.started":"2024-09-28T09:02:05.044969Z"},"trusted":true},"outputs":[],"source":["summary(model, (3, 190, 250))"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:11.725182Z","iopub.status.busy":"2024-09-28T09:02:11.724793Z","iopub.status.idle":"2024-09-28T09:02:11.730350Z","shell.execute_reply":"2024-09-28T09:02:11.729497Z","shell.execute_reply.started":"2024-09-28T09:02:11.725131Z"},"trusted":true},"outputs":[],"source":["# num_features = model.classifier[3].in_features\n","# model.classifier[3] = nn.Linear(1280, 5)\n","model.fc = nn.Linear(4096, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:13.588328Z","iopub.status.busy":"2024-09-28T09:02:13.587938Z","iopub.status.idle":"2024-09-28T09:02:13.595822Z","shell.execute_reply":"2024-09-28T09:02:13.594808Z","shell.execute_reply.started":"2024-09-28T09:02:13.588290Z"},"trusted":true},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:19.178841Z","iopub.status.busy":"2024-09-28T09:02:19.177961Z","iopub.status.idle":"2024-09-28T09:02:19.187184Z","shell.execute_reply":"2024-09-28T09:02:19.186221Z","shell.execute_reply.started":"2024-09-28T09:02:19.178789Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","label_encoder.fit(['Oblong', 'Round', 'Oval', 'Heart', 'Square'])"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:21.152069Z","iopub.status.busy":"2024-09-28T09:02:21.151098Z","iopub.status.idle":"2024-09-28T09:02:21.159884Z","shell.execute_reply":"2024-09-28T09:02:21.159080Z","shell.execute_reply.started":"2024-09-28T09:02:21.152022Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:24.729935Z","iopub.status.busy":"2024-09-28T09:02:24.729549Z","iopub.status.idle":"2024-09-28T09:02:24.734069Z","shell.execute_reply":"2024-09-28T09:02:24.733202Z","shell.execute_reply.started":"2024-09-28T09:02:24.729898Z"},"trusted":true},"outputs":[],"source":["num_epochs = 15"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:26.429244Z","iopub.status.busy":"2024-09-28T09:02:26.428469Z","iopub.status.idle":"2024-09-28T09:02:26.433375Z","shell.execute_reply":"2024-09-28T09:02:26.432333Z","shell.execute_reply.started":"2024-09-28T09:02:26.429202Z"},"trusted":true},"outputs":[],"source":["train_losses = []\n","val_losses = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T09:02:28.608092Z","iopub.status.busy":"2024-09-28T09:02:28.607440Z","iopub.status.idle":"2024-09-28T09:16:26.961405Z","shell.execute_reply":"2024-09-28T09:16:26.960107Z","shell.execute_reply.started":"2024-09-28T09:02:28.608051Z"},"trusted":true},"outputs":[],"source":["for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    model.train()  # Set model to training mode\n","\n","    # Forward Pass (Training)\n","    for data in trainloader:\n","        images, labels = data[0].to(device), data[1]  # Move images to the appropriate device\n","        labels = label_encoder.transform(labels)  # Encode labels\n","        labels = torch.tensor(labels).to(device)  # Convert labels to tensor and move to device\n","\n","        optimizer.zero_grad()  # Clear previous gradients\n","\n","        outputs = model(images)  # Forward pass\n","        loss = criterion(outputs, labels)  # Compute loss\n","\n","        loss.backward()  # Backpropagation (calculate gradients)\n","        optimizer.step()  # Update weights\n","\n","        running_loss += loss.item()\n","\n","    train_losses.append(running_loss / len(trainloader))\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(trainloader):.4f}\")\n","\n","    # Validation (no backpropagation)\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation for validation\n","        for data in valloader:\n","            images, labels = data[0].to(device), data[1]  # Move images to the appropriate device\n","            labels = label_encoder.transform(labels)  # Encode labels\n","            labels = torch.tensor(labels).to(device)  # Convert labels to tensor and move to device\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_losses.append(val_loss / len(valloader))\n","    print(f\"Validation Loss: {val_loss/len(valloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:56:33.795397Z","iopub.status.busy":"2024-09-28T08:56:33.794510Z","iopub.status.idle":"2024-09-28T08:56:34.167667Z","shell.execute_reply":"2024-09-28T08:56:34.166743Z","shell.execute_reply.started":"2024-09-28T08:56:33.795352Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Training and Validation Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T19:48:11.263251Z","iopub.status.busy":"2024-09-27T19:48:11.262431Z","iopub.status.idle":"2024-09-27T19:48:11.333483Z","shell.execute_reply":"2024-09-27T19:48:11.332542Z","shell.execute_reply.started":"2024-09-27T19:48:11.263210Z"},"trusted":true},"outputs":[],"source":["model_path = 'model_MobileNetV3_Greyscal_Augment.pt'\n","torch.save(model.state_dict(), model_path)\n","print(f\"Model saved to {model_path}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Test"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:56:52.359361Z","iopub.status.busy":"2024-09-28T08:56:52.358951Z","iopub.status.idle":"2024-09-28T08:56:52.590811Z","shell.execute_reply":"2024-09-28T08:56:52.589974Z","shell.execute_reply.started":"2024-09-28T08:56:52.359321Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:56:53.773330Z","iopub.status.busy":"2024-09-28T08:56:53.772768Z","iopub.status.idle":"2024-09-28T08:57:12.826221Z","shell.execute_reply":"2024-09-28T08:57:12.825388Z","shell.execute_reply.started":"2024-09-28T08:56:53.773292Z"},"trusted":true},"outputs":[],"source":["test, label_test = read_image(['/kaggle/input/dataset-for-yolo-190x250/Dataset_(190x250)/test'])"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:59:14.346657Z","iopub.status.busy":"2024-09-28T08:59:14.345582Z","iopub.status.idle":"2024-09-28T08:59:14.352042Z","shell.execute_reply":"2024-09-28T08:59:14.351169Z","shell.execute_reply.started":"2024-09-28T08:59:14.346603Z"},"trusted":true},"outputs":[],"source":["transform_test = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.ToTensor(),\n","    transforms.ConvertImageDtype(torch.float32),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n","])"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:59:15.744882Z","iopub.status.busy":"2024-09-28T08:59:15.744495Z","iopub.status.idle":"2024-09-28T08:59:15.749457Z","shell.execute_reply":"2024-09-28T08:59:15.748408Z","shell.execute_reply.started":"2024-09-28T08:59:15.744845Z"},"trusted":true},"outputs":[],"source":["test_dataset = NumpyArrayDataset(test, label_test, transform=transform_test)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:59:17.332924Z","iopub.status.busy":"2024-09-28T08:59:17.331821Z","iopub.status.idle":"2024-09-28T08:59:17.337628Z","shell.execute_reply":"2024-09-28T08:59:17.336605Z","shell.execute_reply.started":"2024-09-28T08:59:17.332874Z"},"trusted":true},"outputs":[],"source":["loader_test = DataLoader(test_dataset, batch_size=4, shuffle=True)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:59:19.236634Z","iopub.status.busy":"2024-09-28T08:59:19.235766Z","iopub.status.idle":"2024-09-28T08:59:19.241191Z","shell.execute_reply":"2024-09-28T08:59:19.240204Z","shell.execute_reply.started":"2024-09-28T08:59:19.236591Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import torch.nn.functional as F  # For softmax\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:59:21.192284Z","iopub.status.busy":"2024-09-28T08:59:21.191889Z","iopub.status.idle":"2024-09-28T08:59:35.066351Z","shell.execute_reply":"2024-09-28T08:59:35.065481Z","shell.execute_reply.started":"2024-09-28T08:59:21.192246Z"},"trusted":true},"outputs":[],"source":["all_preds = []\n","all_labels = []\n","all_confidences = []  # To store confidence scores for each prediction\n","\n","# Validation (no backpropagation)\n","model.eval()  # Set model to evaluation mode\n","val_loss = 0.0\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():  # Disable gradient calculation for validation\n","    for data in loader_test:\n","        images, labels = data[0].to(device), data[1]  # Move images to the appropriate device\n","\n","        # Encode and move labels to the device\n","        encoded_labels = label_encoder.transform(labels)  # Encode labels\n","        encoded_labels = torch.tensor(encoded_labels).to(device)  # Convert labels to tensor\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, encoded_labels)\n","        val_loss += loss.item()\n","\n","        # Apply softmax to get confidence scores for each class\n","        confidences = F.softmax(outputs, dim=1)\n","\n","        # Predictions (choose the class with the highest score)\n","        _, predicted = torch.max(confidences, 1)\n","\n","        # Append the predictions and true labels for classification report\n","        all_preds.extend(predicted.cpu().numpy())  # Move predictions to CPU and store in list\n","        all_labels.extend(encoded_labels.cpu().numpy())  # Move true labels to CPU and store in list\n","        all_confidences.extend(confidences.cpu().numpy())  # Move confidence scores to CPU and store\n","\n","        # Calculate accuracy\n","        total += encoded_labels.size(0)\n","        correct += (predicted == encoded_labels).sum().item()\n","\n","# Compute and print validation loss and accuracy\n","val_loss /= len(loader_test)\n","accuracy = 100 * correct / total\n","print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n","\n","# Classification Report\n","print(\"Classification Report:\")\n","print(classification_report(all_labels, all_preds))\n","\n","# Confusion Matrix\n","conf_matrix = confusion_matrix(all_labels, all_preds)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-28T08:59:39.325074Z","iopub.status.busy":"2024-09-28T08:59:39.324288Z","iopub.status.idle":"2024-09-28T08:59:39.695631Z","shell.execute_reply":"2024-09-28T08:59:39.694728Z","shell.execute_reply.started":"2024-09-28T08:59:39.325032Z"},"trusted":true},"outputs":[],"source":["sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(5), yticklabels=range(5))\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":463280,"sourceId":879701,"sourceType":"datasetVersion"},{"datasetId":1646528,"sourceId":2703153,"sourceType":"datasetVersion"},{"datasetId":2405409,"sourceId":4062693,"sourceType":"datasetVersion"},{"datasetId":4357238,"sourceId":7484847,"sourceType":"datasetVersion"},{"datasetId":5753731,"sourceId":9463256,"sourceType":"datasetVersion"},{"datasetId":5757234,"sourceId":9468026,"sourceType":"datasetVersion"},{"datasetId":5761081,"sourceId":9473069,"sourceType":"datasetVersion"},{"datasetId":5768213,"sourceId":9482715,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
