<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <title>project_isd</title>
    <style>
        video {
            transform: scaleX(-1);
        }
        #video {
            display: block;
            margin: 0 auto;
            width: 100%; /* Full width of the SweetAlert modal */
            height: auto;
            max-width: 600px; /* Maximum width of the video */
        }
        #capture-btn {
            display: block;
            margin: 20px auto;
            padding: 10px 20px;
            background-color: #3085d6;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <!-- background
    <div class="relative overflow-hidden bg-cover bg-no-repeat m-0 p-0" style="background-image: url('./color-bg.jpg'); background-size: cover; background-position: center; height: 100vh;">
        <h1>Find Your Perfect Color</h1>
    </div> -->

    <div id="hiding-camera">
        <!-- open camera -->
        <button type="button" class="text-gray-900 bg-white hover:bg-gray-100 border border-gray-200 focus:ring-4 focus:outline-none focus:ring-gray-100 font-medium rounded-lg text-sm px-5 py-2.5 text-center inline-flex items-center dark:focus:ring-gray-600 dark:bg-gray-800 dark:border-gray-700 dark:text-white dark:hover:bg-gray-700 me-2 mb-2" id="btn-start-camera" onclick="openCamera()">
             <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="size-6">
                <path stroke-linecap="round" stroke-linejoin="round" d="M6.827 6.175A2.31 2.31 0 0 1 5.186 7.23c-.38.054-.757.112-1.134.175C2.999 7.58 2.25 8.507 2.25 9.574V18a2.25 2.25 0 0 0 2.25 2.25h15A2.25 2.25 0 0 0 21.75 18V9.574c0-1.067-.75-1.994-1.802-2.169a47.865 47.865 0 0 0-1.134-.175 2.31 2.31 0 0 1-1.64-1.055l-.822-1.316a2.192 2.192 0 0 0-1.736-1.039 48.774 48.774 0 0 0-5.232 0 2.192 2.192 0 0 0-1.736 1.039l-.821 1.316Z" />
                <path stroke-linecap="round" stroke-linejoin="round" d="M16.5 12.75a4.5 4.5 0 1 1-9 0 4.5 4.5 0 0 1 9 0ZM18.75 10.5h.008v.008h-.008V10.5Z" />
            </svg>&nbsp;Open Camera
        </button>
        <!-- upload file -->
        <div>
            <label class="block mb-2 text-sm font-medium text-gray-900 dark:text-white" for="default_size">Default size</label>
            <input class="block w-[50%] mb-5 text-sm text-gray-900 border border-gray-300 rounded-lg cursor-pointer bg-gray-50 dark:text-gray-400 focus:outline-none dark:bg-gray-700 dark:border-gray-600 dark:placeholder-gray-400" id="default_size" type="file">
        </div>
    </div>

    <script>
        async function loadModels() {
            // Load face detection models from a CDN
            await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
        }
    
        async function openCamera() {
            Swal.fire({
                title: 'Access Your Camera',
                html: `
                    <video id="video" autoplay></video>
                    <button id="capture-btn">Capture Photo</button>
                    <canvas id="canvas" style="display:none;"></canvas>
                `,
                didOpen: async () => {
                    const video = document.querySelector('#video');
                    const canvas = document.querySelector('#canvas');
                    const captureBtn = document.querySelector('#capture-btn');
    
                    // Load face detection models
                    await loadModels();
        
                    // Access user's camera
                    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                        navigator.mediaDevices.getUserMedia({ video: true })
                            .then((stream) => {
                                video.srcObject = stream;
                            })
                            .catch((err) => {
                                Swal.fire('Error', 'Unable to access camera: ' + err.message, 'error');
                            });
                    } else {
                        Swal.fire('Error', 'Your browser does not support camera access.', 'error');
                    }
        
                    // Detect faces in real-time
                    video.addEventListener('play', async () => {
                        const displaySize = { width: video.videoWidth, height: video.videoHeight };
                        faceapi.matchDimensions(canvas, displaySize);
        
                        setInterval(async () => {
                            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
                            if (detections.length > 0) {
                                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                                faceapi.draw.drawDetections(canvas, resizedDetections);
                            }
                        }, 100);
                    });
        
                    // Capture photo when button is clicked
                    captureBtn.addEventListener('click', async () => {
                        const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions());
                        if (detections) {
                            const context = canvas.getContext('2d');
                            const { x, y, width, height } = detections.box;
                            
                            // Set canvas size to 224x224
                            canvas.width = 224;
                            canvas.height = 224;
                            
                            // Flip the captured image horizontally
                            context.translate(224, 0);
                            context.scale(-1, 1);
                            
                            // Draw the image and resize it to 224x224
                            context.drawImage(video, x, y, width, height, 0, 0, 224, 224);
                            const imageUrl = canvas.toDataURL('image/png');
                            
                            Swal.fire({
                                title: 'Captured Photo',
                                imageUrl: imageUrl,
                                imageAlt: 'Captured Photo',
                                confirmButtonText: 'OK',
                            });
                        } else {
                            Swal.fire('Error', 'No face detected', 'error');
                        }
                        
                    });
                    
                },
                willClose: () => {
                    const video = document.querySelector('#video');
                    const stream = video.srcObject;
                    const tracks = stream.getTracks();
        
                    tracks.forEach(function(track) {
                        track.stop();
                    });
                    video.srcObject = null;
                },
                showConfirmButton: false,
                width: '80vw',
            });
        }
    </script>
    
</body>
</html>